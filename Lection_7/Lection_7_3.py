"""
Лекция 7.3.
Парсинг веб-сайтов.
Модуль beautifulsoup
"""

# Модуль beautifulsoup подволяет парсить, те извлекать информацию из других сайтов
# находим модуль beautifulsoup на сайте pypi.org/progects/ ,
# узнаем его версию(beautifulsoup4 4.11.1) и добравляем в requirements.txt
# pip install beautifulsoup4

import requests
import bs4

# на сайте pypi.org/progects/ будем искать модуль на сайте requests
search = 'requests'
response = requests.get(f'https://pypi.org/search/?q={search}')
print(response.status_code)

tree = bs4.BeautifulSoup(response.text, 'html.parser')
# будем разбирать response.text в кот будет html-код,
# чтобы сказать BeautifulSoup, что мы будем разбирать html-код указываем 'html.parser'
print(tree)

# чтобы вытащить информацию с сайта нужно указать selecter
# те некот выражение, каким образом эту информацию можно получить
# выделяем часть страницы (requests 2.28.1), нажимаем правой кнопкой мыши на него и выбираем Исследовать элемент (Inspect)
# открывается инструмент разработчика, в нем мы видим исходный кодстраницы, для удобства можно перенести это окошко вниз (...)
# мы видем дерево элементов, элемент в html назв тэг:
# <p class="package-snippet__description">Python HTTP for Humans.</p>
# p - название тэга, у эл-та может быть несколько классов, может быть id и какое-то содержимое (на пример еще несколько других тегов или текст)

# для того, чтобы вытащить список пакетов, кот пришли в результате, нам нужно понять
# какой элемент отвечает за представление одного элемента в результатах поиска
# <a class="package-snippet" href="/project/requests/">
# возьмем эту информацию и используем ее при разработке парсера

# .select() выбирает некоторые элементы из дерева тэгов
# внутри указываем параметр selector, и указываем название класса, кот начинается с точки (точка - условное обозначение класса)
# print(tree.select('.package-snippet'))
# получаем список элементов, каждый из которых - некот набор html-кода
# это список, значит мы можем перебрать его в цикле

for item in tree.select('.package-snippet'):
# item - тоже html-элемент, значит у него также есть метод select и мы из него можем что-то извлекать
# нам нужно извлечь название модуля, версию и ссылку на этот модуль
# используем select_one, тк внутри этого тэга только один класс с таким именем (у пакета только одно имя)
    name_tag = item.select_one('.package-snippet__name')
    print(name_tag)
# теперь выводятся только тэги с названиями
# чтобы выводились не сами тэки, а только названия используем атрибут .text, кот вытаскивает только текст из тэга
    name = name_tag.text
    version = item.select_one('.package-snippet__version').text
# чтобы вытащить ссылку мы должны обратиться к item.attrs - словарь со всеми атрибутами, те со всеми параметрами, кот указаны в item
# через этот словарь можно получить классы, id и другие атрибуты кот могут быть у тэга
    link = item.attrs['href']
# возвращает относительную ссылку, он указана относительно этого сайта, адрес сайтам там не указан
# чтобы получить полную ссылку конкотинируем адрес ссылки с адресом сайта
    print(name, version, f'https://pypi.org{link}')

# вытаскиваем элементы по id (у нас только одно id = 'content') с помощью #
# выведем оттуда первые 10 символов текста (в начале идут переносы, чтобы их убрать, используем .strip())
# получаем тест сверху нашей страницы сайта
print(tree.select_one("#content").text.strip()[:10])

# чтобы вытащить информацию по тэгам (например все изображения на сайте) в select пишем название тега
# и в результате мы поличим список со всеми картинками
print(tree.select("img"))



# так же можно вытаскивать информацию из других ресурсов
# нужно просто скачать ее из какого-то запроса, дальше ответ положить в парсер и с помощью подобных выражений извлечь ее из парсера


